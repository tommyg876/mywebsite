<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>AI Questions and Future Implications</title>
  <link href="https://fonts.googleapis.com/css?family=Inter:400,600&display=swap" rel="stylesheet">
  <style>
    body {
      background: #f5f6fa;
      font-family: 'Inter', sans-serif;
      margin: 0;
      padding: 0;
      min-height: 100vh;
      display: flex;
      justify-content: center;
      align-items: flex-start;
    }
    .container {
      background: #fff;
      margin: 40px 0;
      padding: 32px;
      border-radius: 16px;
      box-shadow: 0 6px 20px rgba(0,0,0,0.08);
      max-width: 800px;
      width: 98%;
      display: flex;
      flex-direction: column;
      gap: 32px;
      overflow-y: auto;
    }
    header {
      margin-bottom: 16px;
    }
    header h1 {
      font-size: 2rem;
      font-weight: 700;
      margin: 0 0 8px 0;
    }
    .intro {
      font-size: 1rem;
      color: #333;
      margin-bottom: 16px;
    }
    h2 {
      font-size: 1.5rem;
      font-weight: 600;
      margin: 24px 0 16px 0;
      color: #222;
    }
    h3 {
      font-size: 1.25rem;
      font-weight: 600;
      margin: 20px 0 12px 0;
      color: #444;
    }
    p {
      font-size: 0.98rem;
      color: #555;
      line-height: 1.6;
      margin-bottom: 12px;
    }
    em {
      font-style: italic;
      color: #666;
    }
    @media (max-width: 600px) {
      .container {
        padding: 12px;
      }
    }
  </style>
</head>
<body>
  <div class="container">
    <header>
      <h1>AI Questions and Future Implications</h1>
      <p class="intro">A comprehensive exploration of artificial intelligence's current state, bottlenecks, business impacts, and long-term societal transformation.</p>
    </header>

    <h2>1. How have we gotten to where we are today?</h2>
    
    <p>Understanding the current state of AI requires examining how we've scaled and why AI is so important now, rather than 20 years ago. The GPT-3 moment marked a significant turning point in artificial intelligence development.</p>
    
    <p><em>How have we scaled?</em></p>
    
    <p><em>Why is AI so important now, rather than 20 years ago? What was GPT-3 moment?</em></p>
    
    <p><em>How do the models themselves actually work? Is it just next-token prediction, do they reason?</em></p>
    
    <p><em>Different competitors & people in the space at the moment? Innovation breakthroughs that have gotten us to this point? How have scaling laws worked? Trade-offs on Algorithmic Efficiencies vs data vs increased compute? Benchmarks & Eval scores as of current. Sceptical of these as a paradigm.</em></p>

    <h2>2. Bottlenecks to Improve</h2>
    
    <p><em>How far do we get with current models? Leopold thinks current models with unhobbling & increased compute will continue to scale. Meaning elusive, unpredictable algorithmic efficiencies matter less.</em></p>
    
    <p><em>What is needed to get to AGI? Scaffolding? Physical Data? Built-in memory? Ability to complete longer tasks? Better reasoning capabilities? Other pragmatic bottlenecks? Building out data centres & energy? Chip Production from TMSC? Latency for the neural nets? Running out of internet data? Will scaling laws continue? Deep learning has been contingent on these? Will it continue? Bottlenecked by investment following 2030? Theses around current valuations of NVIDIA = amount of GPUS out there based on P/E ratios = need for certain amount of revenue for foundational model companies. Will training methods need to advance? Can RLHF continue to impact? Will RLVR mean that coding/math improves w/o the models generalising necessarily? Is reasoning an actual thing right now? Apple paper says no.</em></p>
    
    <p><em>How does alignment work? Different time scales? Is this a bottleneck or optional in terms of growth? Will regulation stop this?</em></p>

    <h3>Structural Things:</h3>
    
    <p><em>What are current methodologies to pursue algorithmic efficiencies? Diffusion? MOE? MLA?</em></p>
    
    <p><em>Could RL stop being so effective? Why has it been effective to data? Is this a potential bottleneck?</em></p>
    
    <p><em>Will RLHF be enough to have align AI with human intent? How does this issue get solved?</em></p>
    
    <p><em>How does Time Horizon of tasks relate to compute restrictions? Increased reasoning = increased inference compute costs. Is this restricting at all?</em></p>
    
    <p><em>How do agentic workflows come about? System vs Model Level? Is this achieved by OpenAI vs Application-Layer company? Surely, there cannot be a one-size fits all? Does fragmentation still exist?</em></p>
    
    <p><em>Trade-offs on the different areas of improvement? Which are the most important going forward? How will they apply to different areas of the economy?</em></p>
    
    <p><em>Is the grid effective enough to handle all of the energy requirements?</em></p>
    
    <p><em>How effective are reasoning capabilities currently? Will COT/RAG be enough to make it effective? Do we need to rethink these paradigms completely?</em></p>
    
    <p><em>How do agents become better in messy environments?</em></p>
    
    <p><em>Future for OpenAI? What company do they become overtime?</em></p>

    <h2>3. Business Impacts</h2>
    
    <p><em>Is anyone actually meaningfully using AI right now? So, are AI agencies are thing? Will software still be valuable in 3-5 years? Will people make their own? Is coding/programming still a valuable skill to learn regardless of that? Are other, more physical skills, like bio-tech/hardware engineering more valuable than learning to program? Is the cliche of product becoming less valuable true? Brand, Distribution, Data? Are these the actual things that are hard? Is this a myth purported by non-technical people to justify their laziness? Product, GTM & Back-office — my guess is back-office is first to go: IT services, legal, accounting, ops are all inherently digital are therefore will be impacted. GTM still has sales. Software is digital?</em></p>

    <h2>4. Societal Impact of approaching AGI & how it fits in with broader societal issues</h2>
    
    <p>This one is tough & will be endless because AI will not touch, but disrupt everything. From meaning, food, shelter, status.... However, I'll only talk about ones I find generally interesting & understand at least a little bit about. In a weird way, this should become like a blog post about my take on the short-term & medium term future of everything.</p>
    
    <p><em>Impact human jobs? New jobs created? Why wouldn't AI just do them? What is uniquely human? Is there anything?</em></p>
    
    <p><em>Will it differ across nations? Developed v Developing?</em></p>
    
    <p><em>Impact on economic growth? Why do some people think prosperity in the near-term?</em></p>
    
    <p><em>Will land remain valuable because it's about proximity to natural parts of the world that cannot be replicated?</em></p>
    
    <p><em>How does it impact wealth accumulation? Is anyone uniquely positioned in terms of wealth? Real Estate v Digital Biz vs Physical biz vs Startup vs Conglomerate vs Fund vs Product Biz?</em></p>
    
    <p><em>Impact human mating? Since dawn of time, it's been, at least to some extent, been contingent on status. Usually in the form of resources. Maybe it reverts to other forms of status</em></p>
    
    <p><em>Specific business questions: wrappers vs foundational vs other industries. Is it too late? Physical vs digital?</em></p>
    
    <p>Impacts different ages? <em>10 years vs 20 vs 30 vs 40?</em></p>
    
    <p><em>Is it better that people don't know, or are oblivious to this? Would it change their actions? Are their trivial atoms in the big rolling world?</em></p>

    <h2>5. AGI → ASI Long-Term Implications</h2>
    
    <p><em>How do we get self-recursive AI? Is this end-game for human contribution? Is this the fast ticket to ASI? Is ML research as easy as Leopold says?</em></p>
    
    <p><em>Robotics: Is this end-game for human contribution? How quickly will this be deployed? Can we look to history to figure this out? Will there be general robots?</em></p>
    
    <p><em>Biotech: How will genetic/bio eng change the world? Will we still mate? Artificial wombs? If you can pick your character, will there be tradeoffs? Otherwise, how do you differentiate between robots? If Neuralink becomes for more than mentally impaired, do we become robots?</em></p>
    
    <p><em>Climate Change: AI creates energy problems because of compute/water cooling? Does AI create abundance of clean energy; efficient ways to use it & efficient installation for all businesses.</em></p>
    
    <p><em>Material Abundance: Biggest barriers to this are quality food/water/shelter/electricity/healthcare. Western civilisation is dominant because of those simple needs being met. How can ASI accomodate this?</em></p>
    
    <p><em>What does society look like in 50 years? There's a world where AGI/ASI takes longer as funding falls through (highly unlikely), algo efficiencies are harder to come by, we reach a scaling law asymptote. But, what if AGI/ASI does come to fruition?</em></p>
    
    <p><em>Intergalactic space travel? Some people think first VC money into intergalactic company has already happened. Are we extinct? What is possibility of this? Potential calamities that could come from this? Biotech calamities? Engineered pandemics? Weapon creation? Cost reduction of bits mean physical world threats, not just digital ones?</em></p>
    
    <p><em>Does it change how human civilisations interact with one another? More community-orientated without a breakdown of nation states? Will people live all around the world? Live in the sky? On the ocean? In the wilderness?</em></p>
    
    <p><em>Is everyone's life totally customisable? So individualism is easier to come by? All people have to buy other people's food, clothes etc. What if everyone could make it themselves?</em></p>

    <h3>The Path to Abundance</h3>
    
    <p>Effectively we solve a problem in an automated/efficient way, then if that problem is solved... the people that were doing it before in an inefficient way are removed and replaced and must reskill by learning a skill that helps solve a bigger problem that still needs solving.</p>
    
    <p>In theory, on a long enough time horizon, won't all people become engineers or capital allocators because they are the ones who push forward innovation? In an ideal world, there is an abundance of food, an abundance of shelter, an abundance of clothes, an abundance of clean water, an abundance of technology, an abundance of education, abundance of healthcare — this is why everyone keeps going on about abundance because in a futuristic world, everything becomes so cheap and everyone can attain all basic necessities for so cheap that they don't really need much money and it is accessible to everyone. So, even if there is greater wealth inequality, you can be poor and still have great living conditions... Money will not matter.</p>
    
    <p>Even today, money probably matters less than it did 10 years ago. Because with $300 per week you can buy very basic food and shelter... you probably could not have done that a long time ago.</p>
    
    <p>How far is this futuristic reality away? Of course, it exists on a spectrum... it feels like there are still a lot of problems to solve.</p>
    
    <p>What would people do in this new world? Would sports/physical activity become more important? I imagine family and friends time could become more relevant?</p>
  </div>
</body>
</html>
